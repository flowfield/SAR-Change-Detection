# SAR-Change-Detection
![image](https://user-images.githubusercontent.com/105264422/167562559-93a9ae08-070e-47db-8532-5fdb34d111db.png)

1.SID-CNN: 합성개구레이더(SAR) 영상에서 스페클을 제거하는 모델.
2.OICD-CNN: 이미지에서 특징맵을 뽑고 변화를 감지하는 모델.
3.SICD-CNN: SAR 이미지에서 변화를 감지하는 모델.

위의 1, 2번 모델을 사전 학습한 후 둘의 지식을 이용한 전이학습을 통하여 3번 모델을 학습함.

-----------------------------------------------------------------------------------------
![image](https://user-images.githubusercontent.com/105264422/167562698-d9681179-1fc1-4188-9a3f-b207bec99664.png)

합성개구레이더의 특징 중 하나인 스페클의 곱셈 노이즈 성질을 이용하여 SAR-like 이미지 데이터를 생성.

-----------------------------------------------------------------------------------------
![image](https://user-images.githubusercontent.com/105264422/167562726-4c088ed9-e7a8-4cfb-b48c-015c53dffc11.png)

레이어의 개수 및 학습 가능 파라미터의 개수에 따라 결과를 비교

-----------------------------------------------------------------------------------------
![image](https://user-images.githubusercontent.com/105264422/167562759-21b90391-9716-42f8-83d4-33d53957198c.png)

기존의 [32, 64, 128, 256, 512]로 주어져 있던 U-Net++의 커널 사이즈를 [16, 32, 64, 128, 256]으로 줄여 파라미터의 양을 줄이고 속도를 증가시킴.
2번 모델의 두 feature map 사이의 거리를 통해 Contrastive loss function을 이용하여 metric learning을 함.

-----------------------------------------------------------------------------------------
![image](https://user-images.githubusercontent.com/105264422/167562899-cf588e96-8962-45e8-8409-bd1dd392fc6a.png)
![image](https://user-images.githubusercontent.com/105264422/167562968-a4a5e760-03db-454a-ac59-3624ebbe8525.png)

8개 레이어 혹은 16개의 레이어(2종)와 L1, L2, L1+MS-SSIM, L2+MS-SSIM loss function(4종)의 조합으로 총 8개의 결과를 비교

-----------------------------------------------------------------------------------------
![image](https://user-images.githubusercontent.com/105264422/167563019-0e8bb18d-0a09-46c0-b8fd-6cfc417bee0e.png)
![image](https://user-images.githubusercontent.com/105264422/167563045-4f10e14b-2ec2-4486-a74d-28efbbc4e16a.png)

위성 이미지에서 변화를 감지하는 모델을 학습한 결과로 FCN, U-Net++, 제안한 얕은 버전의 U-Net++를 비교.
정성적, 정량적으로 제안한 방법이 가장 좋은 결과를 보이고 있음.

-----------------------------------------------------------------------------------------
실제 SAR 이미지에 3번 모델을 적용한 결과.
End-to-end은 아키텍쳐는 같은 모델에 전이학습을 이용하지 않은 결과, transfer는 전이학습을 이용한 결과.

![image](https://user-images.githubusercontent.com/105264422/167563161-ca096811-6509-41f9-8fb1-6c05b356260e.png)
End-to-end는 학습을 완료한 후에도 변화를 제대로 감지하지 못하고 있지만
전이학습을 이요한 결과는 비교적 정확하게 건물의 변화를 감지하고 있음.

![image](https://user-images.githubusercontent.com/105264422/167563225-1814808e-aadf-4cf4-9d05-95bfe60ef955.png)
변화가 없었던 부분의 비교를 통하여 오탐지율 결과를 얻음.
전이학습을 이용한 결과에서 오탐지 비율이 더 적은 것을 알 수 있음.

-----------------------------------------------------------------------------------------
결론

커다란 하나의 모델을 두 개의 모델로 나누어 학습함으로써
1. 학습 속도 증가
2. 학습 정확도 증가 및 오탐지율 감소

부가적으로 despeckling 모델과 change detection 모델에서 너무 많은 양의 learnable parameter는 오히려 정확도에 악영향을 미침을 알게 됨.
